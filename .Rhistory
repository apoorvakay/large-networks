centroid_nodes = data.frame(list(id = unique(emb_nodes$group),
font.size= rep(70,length(unique(emb_nodes$group))),
shape = rep("square",length(unique(emb_nodes$group))),
group =factor(unique(emb_nodes$group))))
print(centroid_nodes)
print(centroid_pos)
layout_data$centroid_nodes <- centroid_nodes %>%left_join(paper_tf_idf,on="group")%>%left_join(centroid_pos,on="group")
print(layout_data$centroid_nodes)
saveRDS(layout_data,'physics_testdata.Rds')
nodes = data$nodes%>%filter(n_citation!=0)
nodes
source('embedding_functions.R')
library(data.table)
library(dplyr)
library(janeaustenr)
library(tidytext)
data =readRDS('network_layout.Rds')
nodes = data$nodes%>%filter(n_citation!=0)%>%sample_n(300)
edges = data$edges
embedding <- create_network_embedding(
edges = edges,
nodes = nodes,
lsa_dim = 10,
embedding = 'UMAP'
)
cluster_nodes = cluster_embedding(embedding$emb,
10,
method = 'kmeans')
emb_nodes <- as.data.frame(nodes) %>%
cbind(embedding$emb) %>%
#mutate(title = paste(year, title, sep = "\n")) %>%
mutate(group = unlist(cluster_nodes$cluster)) %>%
mutate(cluster = group) %>%
mutate(value = nodes[["n_citation"]]) %>%
select(title,
abstract,
id,
x,
y,
group,
value,
abstract,
venue,
year,
n_citation) %>%
distinct(id, .keep_all = TRUE)
centroid_pos <- emb_nodes%>%
select(x,y,group)%>%
group_by(group)%>%
summarise(x = mean(x),y=mean(y))
emb_edges <- edges %>%
filter(from %in% emb_nodes$id & to %in% emb_nodes$id) %>%
distinct()
layout_data <- list(nodes = emb_nodes, edges = emb_edges)
#
prep_fun = function(x) {
# make text lower case
x = str_to_lower(x)
# remove non-alphanumeric symbols
x = str_replace_all(x, "[^[:alpha:]]", " ")
x = str_replace_all(x,'\\b\\w{1,2}\\b','')
# collapse multiple spaces
x = str_replace_all(x, "\\s+", " ")
stopwords_regex = paste(stopwords::stopwords('en'), collapse = '\\b|\\b')
stopwords_regex = paste0('\\b', stopwords_regex, '\\b')
x = str_replace_all(x, stopwords_regex, '')
x
}
paper_words <- emb_nodes %>%
mutate(text = prep_fun(emb_nodes$title))%>%
unnest_tokens(word, text) %>%
count(group, word, sort = TRUE)
paper_tf_idf <- paper_words %>%
bind_tf_idf(word, group, n)%>%
filter(tf_idf!=0)%>%
group_by(group)%>%
arrange(desc(tf)) %>%
slice(1:3)%>%
group_by(group)%>%
summarise(label=paste(word, collapse=" "))
centroid_nodes = data.frame(list(id = unique(emb_nodes$group),
font.size= rep(70,length(unique(emb_nodes$group))),
shape = rep("square",length(unique(emb_nodes$group))),
group =factor(unique(emb_nodes$group))))
print(centroid_nodes)
print(centroid_pos)
layout_data$centroid_nodes <- centroid_nodes %>%left_join(paper_tf_idf,on="group")%>%left_join(centroid_pos,on="group")
print(layout_data$centroid_nodes)
saveRDS(layout_data,'physics_testdata.Rds')
source('embedding_functions.R')
library(data.table)
library(dplyr)
library(janeaustenr)
library(tidytext)
data =readRDS('network_layout.Rds')
nodes = data$nodes%>%filter(n_citation!=0)%>%sample_n(300)
edges = data$edges
embedding <- create_network_embedding(
edges = edges,
nodes = nodes,
lsa_dim = 10,
embedding = 'UMAP'
)
cluster_nodes = cluster_embedding(embedding$emb,
5,
method = 'kmeans')
emb_nodes <- as.data.frame(nodes) %>%
cbind(embedding$emb) %>%
#mutate(title = paste(year, title, sep = "\n")) %>%
mutate(group = unlist(cluster_nodes$cluster)) %>%
mutate(cluster = group) %>%
mutate(value = nodes[["n_citation"]]) %>%
select(title,
abstract,
id,
x,
y,
group,
value,
abstract,
venue,
year,
n_citation) %>%
distinct(id, .keep_all = TRUE)
centroid_pos <- emb_nodes%>%
select(x,y,group)%>%
group_by(group)%>%
summarise(x = mean(x),y=mean(y))
emb_edges <- edges %>%
filter(from %in% emb_nodes$id & to %in% emb_nodes$id) %>%
distinct()
layout_data <- list(nodes = emb_nodes, edges = emb_edges)
#
prep_fun = function(x) {
# make text lower case
x = str_to_lower(x)
# remove non-alphanumeric symbols
x = str_replace_all(x, "[^[:alpha:]]", " ")
x = str_replace_all(x,'\\b\\w{1,2}\\b','')
# collapse multiple spaces
x = str_replace_all(x, "\\s+", " ")
stopwords_regex = paste(stopwords::stopwords('en'), collapse = '\\b|\\b')
stopwords_regex = paste0('\\b', stopwords_regex, '\\b')
x = str_replace_all(x, stopwords_regex, '')
x
}
paper_words <- emb_nodes %>%
mutate(text = prep_fun(emb_nodes$title))%>%
unnest_tokens(word, text) %>%
count(group, word, sort = TRUE)
paper_tf_idf <- paper_words %>%
bind_tf_idf(word, group, n)%>%
filter(tf_idf!=0)%>%
group_by(group)%>%
arrange(desc(tf)) %>%
slice(1:3)%>%
group_by(group)%>%
summarise(label=paste(word, collapse=" "))
centroid_nodes = data.frame(list(id = unique(emb_nodes$group),
font.size= rep(70,length(unique(emb_nodes$group))),
shape = rep("square",length(unique(emb_nodes$group))),
group =factor(unique(emb_nodes$group))))
print(centroid_nodes)
print(centroid_pos)
layout_data$centroid_nodes <- centroid_nodes %>%left_join(paper_tf_idf,on="group")%>%left_join(centroid_pos,on="group")
print(layout_data$centroid_nodes)
saveRDS(layout_data,'physics_testdata.Rds')
source('embedding_functions.R')
library(data.table)
library(dplyr)
library(janeaustenr)
library(tidytext)
data =readRDS('network_layout.Rds')
nodes = data$nodes%>%filter(n_citation!=0)%>%sample_n(100)
edges = data$edges
embedding <- create_network_embedding(
edges = edges,
nodes = nodes,
lsa_dim = 10,
embedding = 'UMAP'
)
cluster_nodes = cluster_embedding(embedding$emb,
5,
method = 'kmeans')
emb_nodes <- as.data.frame(nodes) %>%
cbind(embedding$emb) %>%
#mutate(title = paste(year, title, sep = "\n")) %>%
mutate(group = unlist(cluster_nodes$cluster)) %>%
mutate(cluster = group) %>%
mutate(value = nodes[["n_citation"]]) %>%
select(title,
abstract,
id,
x,
y,
group,
value,
abstract,
venue,
year,
n_citation) %>%
distinct(id, .keep_all = TRUE)
centroid_pos <- emb_nodes%>%
select(x,y,group)%>%
group_by(group)%>%
summarise(x = mean(x),y=mean(y))
emb_edges <- edges %>%
filter(from %in% emb_nodes$id & to %in% emb_nodes$id) %>%
distinct()
layout_data <- list(nodes = emb_nodes, edges = emb_edges)
#
prep_fun = function(x) {
# make text lower case
x = str_to_lower(x)
# remove non-alphanumeric symbols
x = str_replace_all(x, "[^[:alpha:]]", " ")
x = str_replace_all(x,'\\b\\w{1,2}\\b','')
# collapse multiple spaces
x = str_replace_all(x, "\\s+", " ")
stopwords_regex = paste(stopwords::stopwords('en'), collapse = '\\b|\\b')
stopwords_regex = paste0('\\b', stopwords_regex, '\\b')
x = str_replace_all(x, stopwords_regex, '')
x
}
paper_words <- emb_nodes %>%
mutate(text = prep_fun(emb_nodes$title))%>%
unnest_tokens(word, text) %>%
count(group, word, sort = TRUE)
paper_tf_idf <- paper_words %>%
bind_tf_idf(word, group, n)%>%
filter(tf_idf!=0)%>%
group_by(group)%>%
arrange(desc(tf)) %>%
slice(1:3)%>%
group_by(group)%>%
summarise(label=paste(word, collapse=" "))
centroid_nodes = data.frame(list(id = unique(emb_nodes$group),
font.size= rep(70,length(unique(emb_nodes$group))),
shape = rep("square",length(unique(emb_nodes$group))),
group =factor(unique(emb_nodes$group))))
print(centroid_nodes)
print(centroid_pos)
layout_data$centroid_nodes <- centroid_nodes %>%left_join(paper_tf_idf,on="group")%>%left_join(centroid_pos,on="group")
print(layout_data$centroid_nodes)
saveRDS(layout_data,'physics_testdata.Rds')
source('embedding_functions.R')
library(data.table)
library(dplyr)
library(janeaustenr)
library(tidytext)
data =readRDS('network_layout.Rds')
nodes = data$nodes%>%filter(n_citation!=0)%>%sample_n(100)
edges = data$edges
#filtering
g <- graph_from_data_frame(edges, vertices = nodes$id)
source('embedding_functions.R')
library(data.table)
library(dplyr)
library(janeaustenr)
library(tidytext)
data =readRDS('network_layout.Rds')
nodes = data$nodes
edges = data$edges
#filtering
g <- graph_from_data_frame(edges, vertices = nodes$id)
df_deg <-
data.frame(list(id = names(V(g)), deg = degree(g))) %>%
filter(deg > 3)
nodes <- nodes %>%
filter(id %in% df_deg$id)
embedding <- create_network_embedding(
edges = edges,
nodes = nodes,
lsa_dim = 10,
embedding = 'UMAP'
)
cluster_nodes = cluster_embedding(embedding$emb,
5,
method = 'kmeans')
emb_nodes <- as.data.frame(nodes) %>%
cbind(embedding$emb) %>%
#mutate(title = paste(year, title, sep = "\n")) %>%
mutate(group = unlist(cluster_nodes$cluster)) %>%
mutate(cluster = group) %>%
mutate(value = nodes[["n_citation"]]) %>%
select(title,
abstract,
id,
x,
y,
group,
value,
abstract,
venue,
year,
n_citation) %>%
distinct(id, .keep_all = TRUE)
centroid_pos <- emb_nodes%>%
select(x,y,group)%>%
group_by(group)%>%
summarise(x = mean(x),y=mean(y))
emb_edges <- edges %>%
filter(from %in% emb_nodes$id & to %in% emb_nodes$id) %>%
distinct()
layout_data <- list(nodes = emb_nodes, edges = emb_edges)
#
prep_fun = function(x) {
# make text lower case
x = str_to_lower(x)
# remove non-alphanumeric symbols
x = str_replace_all(x, "[^[:alpha:]]", " ")
x = str_replace_all(x,'\\b\\w{1,2}\\b','')
# collapse multiple spaces
x = str_replace_all(x, "\\s+", " ")
stopwords_regex = paste(stopwords::stopwords('en'), collapse = '\\b|\\b')
stopwords_regex = paste0('\\b', stopwords_regex, '\\b')
x = str_replace_all(x, stopwords_regex, '')
x
}
paper_words <- emb_nodes %>%
mutate(text = prep_fun(emb_nodes$title))%>%
unnest_tokens(word, text) %>%
count(group, word, sort = TRUE)
paper_tf_idf <- paper_words %>%
bind_tf_idf(word, group, n)%>%
filter(tf_idf!=0)%>%
group_by(group)%>%
arrange(desc(tf)) %>%
slice(1:3)%>%
group_by(group)%>%
summarise(label=paste(word, collapse=" "))
centroid_nodes = data.frame(list(id = unique(emb_nodes$group),
font.size= rep(70,length(unique(emb_nodes$group))),
shape = rep("square",length(unique(emb_nodes$group))),
group =factor(unique(emb_nodes$group))))
layout_data$centroid_nodes <- centroid_nodes %>%left_join(paper_tf_idf,on="group")%>%left_join(centroid_pos,on="group")
print(layout_data$centroid_nodes)
saveRDS(layout_data,'physics_testdata.Rds')
print(nodes)
source('embedding_functions.R')
library(data.table)
library(dplyr)
library(janeaustenr)
library(tidytext)
data =readRDS('network_layout.Rds')
nodes = data$nodes
edges = data$edges
#filtering
g <- graph_from_data_frame(edges, vertices = nodes$id)
df_deg <-
data.frame(list(id = names(V(g)), deg = degree(g))) %>%
filter(deg > 3)
nodes <- nodes %>%
filter(id %in% df_deg$id)
print(nodes)
embedding <- create_network_embedding(
edges = edges,
nodes = nodes,
lsa_dim = 10,
embedding = 'UMAP'
)
cluster_nodes = cluster_embedding(embedding$emb,
5,
method = 'kmeans')
emb_nodes <- as.data.frame(nodes) %>%
cbind(embedding$emb) %>%
#mutate(title = paste(year, title, sep = "\n")) %>%
mutate(group = unlist(cluster_nodes$cluster)) %>%
mutate(cluster = group) %>%
mutate(value = nodes[["n_citation"]]) %>%
select(title,
abstract,
id,
x,
y,
group,
value,
abstract,
venue,
year,
n_citation) %>%
distinct(id, .keep_all = TRUE)
centroid_pos <- emb_nodes%>%
select(x,y,group)%>%
group_by(group)%>%
summarise(x = mean(x),y=mean(y))
emb_edges <- edges %>%
filter(from %in% emb_nodes$id & to %in% emb_nodes$id) %>%
distinct()
layout_data <- list(nodes = emb_nodes, edges = emb_edges)
#
prep_fun = function(x) {
# make text lower case
x = str_to_lower(x)
# remove non-alphanumeric symbols
x = str_replace_all(x, "[^[:alpha:]]", " ")
x = str_replace_all(x,'\\b\\w{1,2}\\b','')
# collapse multiple spaces
x = str_replace_all(x, "\\s+", " ")
stopwords_regex = paste(stopwords::stopwords('en'), collapse = '\\b|\\b')
stopwords_regex = paste0('\\b', stopwords_regex, '\\b')
x = str_replace_all(x, stopwords_regex, '')
x
}
paper_words <- emb_nodes %>%
mutate(text = prep_fun(emb_nodes$title))%>%
unnest_tokens(word, text) %>%
count(group, word, sort = TRUE)
paper_tf_idf <- paper_words %>%
bind_tf_idf(word, group, n)%>%
filter(tf_idf!=0)%>%
group_by(group)%>%
arrange(desc(tf)) %>%
slice(1:3)%>%
group_by(group)%>%
summarise(label=paste(word, collapse=" "))
centroid_nodes = data.frame(list(id = unique(emb_nodes$group),
font.size= rep(70,length(unique(emb_nodes$group))),
shape = rep("square",length(unique(emb_nodes$group))),
group =factor(unique(emb_nodes$group))))
layout_data$centroid_nodes <- centroid_nodes %>%left_join(paper_tf_idf,on="group")%>%left_join(centroid_pos,on="group")
print(layout_data$centroid_nodes)
saveRDS(layout_data,'physics_testdata.Rds')
source("~/GitHub/citation_networks_viz/create_datasets.R")
source("~/GitHub/citation_networks_viz/create_datasets.R")
runApp()
runApp()
source('embedding_functions.R')
library(data.table)
library(dplyr)
library(janeaustenr)
library(tidytext)
data =readRDS('network_layout.Rds')
nodes = data$nodes
edges = data$edges
#filtering
g <- graph_from_data_frame(edges, vertices = nodes$id)
df_deg <-
data.frame(list(id = names(V(g)), deg = degree(g))) %>%
filter(deg > 3)
nodes <- nodes %>%
filter(id %in% df_deg$id)
print(nodes)
embedding <- create_network_embedding(
edges = edges,
nodes = nodes,
lsa_dim = 10,
embedding = 'FR'
)
cluster_nodes = cluster_embedding(embedding$emb,
5,
method = 'kmeans')
emb_nodes <- as.data.frame(nodes) %>%
cbind(embedding$emb) %>%
#mutate(title = paste(year, title, sep = "\n")) %>%
mutate(group = unlist(cluster_nodes$cluster)) %>%
mutate(cluster = group) %>%
mutate(value = nodes[["n_citation"]]) %>%
select(title,
abstract,
id,
x,
y,
group,
value,
abstract,
venue,
year,
n_citation) %>%
distinct(id, .keep_all = TRUE)
centroid_pos <- emb_nodes%>%
select(x,y,group)%>%
group_by(group)%>%
summarise(x = mean(x),y=mean(y))
emb_edges <- edges %>%
filter(from %in% emb_nodes$id & to %in% emb_nodes$id) %>%
distinct()
layout_data <- list(nodes = emb_nodes, edges = emb_edges)
#
prep_fun = function(x) {
# make text lower case
x = str_to_lower(x)
# remove non-alphanumeric symbols
x = str_replace_all(x, "[^[:alpha:]]", " ")
x = str_replace_all(x,'\\b\\w{1,2}\\b','')
# collapse multiple spaces
x = str_replace_all(x, "\\s+", " ")
stopwords_regex = paste(stopwords::stopwords('en'), collapse = '\\b|\\b')
stopwords_regex = paste0('\\b', stopwords_regex, '\\b')
x = str_replace_all(x, stopwords_regex, '')
x
}
paper_words <- emb_nodes %>%
mutate(text = prep_fun(emb_nodes$title))%>%
unnest_tokens(word, text) %>%
count(group, word, sort = TRUE)
paper_tf_idf <- paper_words %>%
bind_tf_idf(word, group, n)%>%
filter(tf_idf!=0)%>%
group_by(group)%>%
arrange(desc(tf)) %>%
slice(1:3)%>%
group_by(group)%>%
summarise(label=paste(word, collapse=" "))
centroid_nodes = data.frame(list(id = unique(emb_nodes$group),
font.size= rep(70,length(unique(emb_nodes$group))),
shape = rep("square",length(unique(emb_nodes$group))),
group =factor(unique(emb_nodes$group))))
layout_data$centroid_nodes <- centroid_nodes %>%left_join(paper_tf_idf,on="group")%>%left_join(centroid_pos,on="group")
print(layout_data$centroid_nodes)
saveRDS(layout_data,'computer_science_testdata_spring.Rds')
nodes
